import pandas as pd
import os
import glob
import numpy as np
import re
from pathlib import Path
from collections import Counter

def extract_city_comprehensive_features(city_df, city_name):
    """
    åŸºäºå¤–å›½æ¸¸å®¢åå¥½æå–åŸå¸‚ç»¼åˆç‰¹å¾
    """
    features = {'city': city_name}
    
    # ===================== 1. æ™¯ç‚¹å¸å¼•åŠ›æŒ‡æ ‡ =====================
    # è¯„åˆ†ç›¸å…³
    valid_scores = pd.to_numeric(city_df['è¯„åˆ†'].replace('', np.nan), errors='coerce').dropna()
    if len(valid_scores) > 0:
        features['å¹³å‡æ™¯ç‚¹è¯„åˆ†'] = valid_scores.mean()
        features['é«˜è´¨é‡æ™¯ç‚¹æ•°'] = len(valid_scores[valid_scores >= 4.5])
        features['é¡¶çº§æ™¯ç‚¹æ•°'] = len(valid_scores[valid_scores >= 4.8])  # é¡¶çº§æ™¯ç‚¹
    else:
        features['å¹³å‡æ™¯ç‚¹è¯„åˆ†'] = 0
        features['é«˜è´¨é‡æ™¯ç‚¹æ•°'] = 0
        features['é¡¶çº§æ™¯ç‚¹æ•°'] = 0
    
    features['æ™¯ç‚¹æ€»æ•°'] = len(city_df)
    
    # å»ºè®®æ¸¸ç©æ—¶é—´ï¼ˆåæ˜ æ™¯ç‚¹æ·±åº¦ï¼‰
    play_times = city_df['å»ºè®®æ¸¸ç©æ—¶é—´'].fillna('').astype(str)
    long_visit_count = 0  # éœ€è¦é•¿æ—¶é—´æ¸¸è§ˆçš„æ™¯ç‚¹
    for time_str in play_times:
        if any(keyword in time_str for keyword in ['å¤©', 'åŠå¤©', 'ä¸€å¤©', '2å°æ—¶ä»¥ä¸Š', '3å°æ—¶ä»¥ä¸Š']):
            long_visit_count += 1
    features['æ·±åº¦æ¸¸æ™¯ç‚¹æ¯”ä¾‹'] = long_visit_count / len(city_df) if len(city_df) > 0 else 0
    
    # ===================== 2. äººæ–‡åº•è•´æŒ‡æ ‡ =====================
    introductions = city_df['ä»‹ç»'].fillna('').str.lower()
    
    # å†å²æ–‡åŒ–å…³é”®è¯
    culture_keywords = ['å¤', 'å†å²', 'æ–‡åŒ–', 'é—å€', 'åšç‰©', 'å¯º', 'åº™', 'å®«', 'æ•…å±…', 
                       'å¤é•‡', 'å¤åŸ', 'ä¼ ç»Ÿ', 'éé—', 'æ–‡ç‰©', 'å¤å»ºç­‘', 'çš‡å®¶', 'å¸ç‹']
    
    # å®—æ•™æ–‡åŒ–å…³é”®è¯  
    religion_keywords = ['ä½›', 'é“', 'å¯ºåº™', 'é“è§‚', 'æ•™å ‚', 'æ¸…çœŸå¯º', 'ç¦…', 'ä½›æ•™', 'é“æ•™']
    
    # ç°ä»£æ–‡åŒ–å…³é”®è¯
    modern_culture_keywords = ['åšç‰©é¦†', 'ç¾æœ¯é¦†', 'è‰ºæœ¯', 'æ–‡åŒ–ä¸­å¿ƒ', 'å‰§é™¢', 'éŸ³ä¹å…']
    
    culture_score = sum([intro.count(word) for intro in introductions for word in culture_keywords])
    religion_score = sum([intro.count(word) for intro in introductions for word in religion_keywords])
    modern_culture_score = sum([intro.count(word) for intro in introductions for word in modern_culture_keywords])
    
    features['å†å²æ–‡åŒ–æŒ‡æ•°'] = culture_score / len(city_df) if len(city_df) > 0 else 0
    features['å®—æ•™æ–‡åŒ–æŒ‡æ•°'] = religion_score / len(city_df) if len(city_df) > 0 else 0
    features['ç°ä»£æ–‡åŒ–æŒ‡æ•°'] = modern_culture_score / len(city_df) if len(city_df) > 0 else 0
    
    # ===================== 3. ç¯å¢ƒä¸ç”Ÿæ€æŒ‡æ ‡ =====================
    nature_keywords = ['å±±', 'æ°´', 'æ¹–', 'å…¬å›­', 'æ£®æ—', 'èŠ±å›­', 'æ¤ç‰©å›­', 'æ¹¿åœ°', 
                      'è‡ªç„¶', 'ç”Ÿæ€', 'ç»¿åœ°', 'é£æ™¯', 'æ™¯è§‚', 'èŠ±æµ·', 'ç«¹æ—', 'æºªæµ']
    
    nature_score = sum([intro.count(word) for intro in introductions for word in nature_keywords])
    features['è‡ªç„¶ç”Ÿæ€æŒ‡æ•°'] = nature_score / len(city_df) if len(city_df) > 0 else 0
    
    # ç©ºæ°”è´¨é‡ç›¸å…³ï¼ˆé€šè¿‡æ™¯ç‚¹ç±»å‹é—´æ¥åæ˜ ï¼‰
    outdoor_keywords = ['æˆ·å¤–', 'ç™»å±±', 'å¾’æ­¥', 'éœ²è¥', 'è§‚æ™¯', 'çœºæœ›']
    outdoor_score = sum([intro.count(word) for intro in introductions for word in outdoor_keywords])
    features['æˆ·å¤–æ´»åŠ¨æŒ‡æ•°'] = outdoor_score / len(city_df) if len(city_df) > 0 else 0
    
    # ===================== 4. åŸå¸‚è§„æ¨¡ä¸ç°ä»£åŒ–æŒ‡æ•° =====================
    urban_keywords = ['å¹¿åœº', 'å•†ä¸š', 'è´­ç‰©', 'ä¸­å¿ƒ', 'ç°ä»£', 'å›½é™…', 'éƒ½å¸‚', 'å¤§å‹', 
                     'ç»¼åˆä½“', 'åœ°æ ‡', 'æ‘©å¤©', 'é«˜æ¥¼', 'CBD']
    
    urban_score = sum([intro.count(word) for intro in introductions for word in urban_keywords])
    features['åŸå¸‚ç°ä»£åŒ–æŒ‡æ•°'] = urban_score / len(city_df) if len(city_df) > 0 else 0
    
    # æ™¯ç‚¹åˆ†å¸ƒå¹¿åº¦ï¼ˆé€šè¿‡åœ°å€åˆ¤æ–­ï¼‰
    addresses = city_df['åœ°å€'].fillna('').astype(str)
    districts = set()
    for addr in addresses:
        # æå–åŒº/å¿åç§°
        district_match = re.findall(r'[\u4e00-\u9fff]+[åŒºå¿å¸‚]', addr)
        districts.update(district_match)
    features['åŸå¸‚è¦†ç›–å¹¿åº¦'] = len(districts)
    
    # ===================== 5. äº¤é€šä¾¿åˆ©æ€§æŒ‡æ ‡ =====================
    # é€šè¿‡å¼€æ”¾æ—¶é—´åˆ¤æ–­ä¾¿åˆ©æ€§
    opening_hours = city_df['å¼€æ”¾æ—¶é—´'].fillna('').astype(str)
    convenient_hours = 0
    for hours in opening_hours:
        if any(keyword in hours for keyword in ['å…¨å¤©', '24å°æ—¶', 'å…¨å¹´', 'æ— éœ€é¢„çº¦']):
            convenient_hours += 1
    features['äº¤é€šä¾¿åˆ©æŒ‡æ•°'] = convenient_hours / len(city_df) if len(city_df) > 0 else 0
    
    # äº¤é€šæ¢çº½ç›¸å…³æ™¯ç‚¹
    transport_keywords = ['ç«™', 'æœºåœº', 'æ¸¯å£', 'ç å¤´', 'äº¤é€š', 'æ¢çº½', 'åœ°é“']
    transport_score = sum([intro.count(word) for intro in introductions for word in transport_keywords])
    features['äº¤é€šæ¢çº½æŒ‡æ•°'] = transport_score / len(city_df) if len(city_df) > 0 else 0
    
    # ===================== 6. æ°”å€™èˆ’é€‚åº¦æŒ‡æ ‡ =====================
    season_recommendations = city_df['å»ºè®®å­£èŠ‚'].fillna('').astype(str)
    
    # å…¨å¹´é€‚å®œæ¸¸è§ˆçš„æ™¯ç‚¹æ¯”ä¾‹
    all_season_count = 0
    spring_summer_count = 0  # æ˜¥å¤é€‚å®œ
    
    for season in season_recommendations:
        if any(keyword in season for keyword in ['å››å­£', 'å…¨å¹´', 'ä»»ä½•æ—¶å€™', 'æ˜¥å¤ç§‹å†¬']):
            all_season_count += 1
        elif any(keyword in season for keyword in ['æ˜¥', 'å¤', 'æ¸©æš–', '4æœˆ', '5æœˆ', '6æœˆ', '7æœˆ', '8æœˆ', '9æœˆ']):
            spring_summer_count += 1
    
    features['å…¨å­£èŠ‚é€‚å®œæŒ‡æ•°'] = all_season_count / len(city_df) if len(city_df) > 0 else 0
    features['æ˜¥å¤é€‚å®œæŒ‡æ•°'] = spring_summer_count / len(city_df) if len(city_df) > 0 else 0
    
    # ===================== 7. ç¾é£Ÿæ–‡åŒ–æŒ‡æ•° =====================
    food_keywords = ['ç¾é£Ÿ', 'å°åƒ', 'ç‰¹è‰²', 'é¤', 'æ–™ç†', 'èœ', 'èŒ¶', 'é…’', 'ååƒ', 
                    'é£å‘³', 'ä¼ ç»Ÿé£Ÿ', 'å½“åœ°', 'ç‰¹äº§', 'å°é£Ÿ', 'å¤œå¸‚']
    
    food_score = sum([intro.count(word) for intro in introductions for word in food_keywords])
    features['ç¾é£Ÿæ–‡åŒ–æŒ‡æ•°'] = food_score / len(city_df) if len(city_df) > 0 else 0
    
    # èŒ¶æ–‡åŒ–ç‰¹åˆ«æŒ‡æ ‡ï¼ˆå¤–å›½æ¸¸å®¢æ„Ÿå…´è¶£ï¼‰
    tea_keywords = ['èŒ¶', 'èŒ¶é¦†', 'èŒ¶å®¤', 'èŒ¶æ–‡åŒ–', 'å“èŒ¶', 'èŒ¶è‰º']
    tea_score = sum([intro.count(word) for intro in introductions for word in tea_keywords])
    features['èŒ¶æ–‡åŒ–æŒ‡æ•°'] = tea_score / len(city_df) if len(city_df) > 0 else 0
    
    # ===================== 8. å›½é™…åŒ–ä¸æœåŠ¡æŒ‡æ•° =====================
    # é—¨ç¥¨ä»·æ ¼åˆç†æ€§
    ticket_prices = []
    free_attractions = 0
    
    for ticket_info in city_df['é—¨ç¥¨'].fillna('{}'):
        try:
            if isinstance(ticket_info, str) and 'å…è´¹' in ticket_info:
                free_attractions += 1
            elif isinstance(ticket_info, str) and ticket_info.strip():
                price_nums = re.findall(r'Â¥(\d+)', str(ticket_info))
                if price_nums:
                    ticket_prices.extend([int(p) for p in price_nums])
        except:
            continue
    
    features['å…è´¹æ™¯ç‚¹æ¯”ä¾‹'] = free_attractions / len(city_df) if len(city_df) > 0 else 0
    features['å¹³å‡é—¨ç¥¨ä»·æ ¼'] = np.mean(ticket_prices) if ticket_prices else 50
    
    # æœåŠ¡è´¨é‡ï¼ˆé€šè¿‡å°è´´å£«å®Œå–„åº¦åˆ¤æ–­ï¼‰
    tips_quality = len(city_df[city_df['å°è´´å£«'].fillna('').str.len() > 20])
    features['æœåŠ¡è´¨é‡æŒ‡æ•°'] = tips_quality / len(city_df) if len(city_df) > 0 else 0
    
    return features

def process_all_cities_comprehensive(folder_path):
    """
    å¤„ç†æ‰€æœ‰åŸå¸‚æ•°æ® - å¤–å›½æ¸¸å®¢ç»¼åˆè¯„ä»·ç‰ˆæœ¬
    """
    csv_files = glob.glob(os.path.join(folder_path, "*.csv"))
    all_city_features = []
    
    print(f"å‘ç° {len(csv_files)} ä¸ªåŸå¸‚æ•°æ®æ–‡ä»¶")
    
    for csv_file in csv_files:
        city_name = Path(csv_file).stem
        
        try:
            city_df = pd.read_csv(csv_file, encoding='utf-8')
            print(f"å¤„ç†åŸå¸‚: {city_name}, æ™¯ç‚¹æ•°é‡: {len(city_df)}")
            
            city_features = extract_city_comprehensive_features(city_df, city_name)
            all_city_features.append(city_features)
            
        except Exception as e:
            print(f"å¤„ç† {city_name} æ—¶å‡ºé”™: {e}")
            continue
    
    return pd.DataFrame(all_city_features)

def comprehensive_evaluation_for_foreign_tourists(city_features_df):
    """
    åŸºäºå¤–å›½æ¸¸å®¢åå¥½çš„ç»¼åˆè¯„ä»·å’Œå½’ä¸€åŒ–
    """
    # éœ€è¦å½’ä¸€åŒ–çš„æŒ‡æ ‡
    feature_cols = [
        'å¹³å‡æ™¯ç‚¹è¯„åˆ†', 'é«˜è´¨é‡æ™¯ç‚¹æ•°', 'é¡¶çº§æ™¯ç‚¹æ•°', 'æ™¯ç‚¹æ€»æ•°', 'æ·±åº¦æ¸¸æ™¯ç‚¹æ¯”ä¾‹',
        'å†å²æ–‡åŒ–æŒ‡æ•°', 'å®—æ•™æ–‡åŒ–æŒ‡æ•°', 'ç°ä»£æ–‡åŒ–æŒ‡æ•°', 'è‡ªç„¶ç”Ÿæ€æŒ‡æ•°', 'æˆ·å¤–æ´»åŠ¨æŒ‡æ•°',
        'åŸå¸‚ç°ä»£åŒ–æŒ‡æ•°', 'åŸå¸‚è¦†ç›–å¹¿åº¦', 'äº¤é€šä¾¿åˆ©æŒ‡æ•°', 'äº¤é€šæ¢çº½æŒ‡æ•°',
        'å…¨å­£èŠ‚é€‚å®œæŒ‡æ•°', 'æ˜¥å¤é€‚å®œæŒ‡æ•°', 'ç¾é£Ÿæ–‡åŒ–æŒ‡æ•°', 'èŒ¶æ–‡åŒ–æŒ‡æ•°',
        'å…è´¹æ™¯ç‚¹æ¯”ä¾‹', 'å¹³å‡é—¨ç¥¨ä»·æ ¼', 'æœåŠ¡è´¨é‡æŒ‡æ•°'
    ]
    
    # å½’ä¸€åŒ–å¤„ç†
    for col in feature_cols:
        if col in city_features_df.columns:
            min_val = city_features_df[col].min()
            max_val = city_features_df[col].max()
            
            # é—¨ç¥¨ä»·æ ¼æ˜¯è´Ÿå‘æŒ‡æ ‡
            if col == 'å¹³å‡é—¨ç¥¨ä»·æ ¼':
                city_features_df[col + '_norm'] = (max_val - city_features_df[col]) / (max_val - min_val) if max_val != min_val else 0.5
            else:
                city_features_df[col + '_norm'] = (city_features_df[col] - min_val) / (max_val - min_val) if max_val != min_val else 0.5
    
    # å¤–å›½æ¸¸å®¢åå¥½æƒé‡è®¾è®¡
    weights = {
        # æ™¯ç‚¹å¸å¼•åŠ› (30%)
        'å¹³å‡æ™¯ç‚¹è¯„åˆ†_norm': 0.12,
        'é«˜è´¨é‡æ™¯ç‚¹æ•°_norm': 0.10,
        'é¡¶çº§æ™¯ç‚¹æ•°_norm': 0.08,
        
        # äººæ–‡åº•è•´ (25%) - å¤–å›½æ¸¸å®¢æœ€æ„Ÿå…´è¶£
        'å†å²æ–‡åŒ–æŒ‡æ•°_norm': 0.15,
        'å®—æ•™æ–‡åŒ–æŒ‡æ•°_norm': 0.06,
        'ç°ä»£æ–‡åŒ–æŒ‡æ•°_norm': 0.04,
        
        # è‡ªç„¶ç¯å¢ƒ (15%)
        'è‡ªç„¶ç”Ÿæ€æŒ‡æ•°_norm': 0.10,
        'æˆ·å¤–æ´»åŠ¨æŒ‡æ•°_norm': 0.05,
        
        # åŸå¸‚è§„æ¨¡ä¸ä¾¿åˆ©æ€§ (15%)
        'åŸå¸‚ç°ä»£åŒ–æŒ‡æ•°_norm': 0.05,
        'åŸå¸‚è¦†ç›–å¹¿åº¦_norm': 0.04,
        'äº¤é€šä¾¿åˆ©æŒ‡æ•°_norm': 0.04,
        'äº¤é€šæ¢çº½æŒ‡æ•°_norm': 0.02,
        
        # æ°”å€™èˆ’é€‚åº¦ (8%)
        'å…¨å­£èŠ‚é€‚å®œæŒ‡æ•°_norm': 0.05,
        'æ˜¥å¤é€‚å®œæŒ‡æ•°_norm': 0.03,
        
        # ç¾é£Ÿæ–‡åŒ– (5%)
        'ç¾é£Ÿæ–‡åŒ–æŒ‡æ•°_norm': 0.03,
        'èŒ¶æ–‡åŒ–æŒ‡æ•°_norm': 0.02,
        
        # æ€§ä»·æ¯”ä¸æœåŠ¡ (2%)
        'å…è´¹æ™¯ç‚¹æ¯”ä¾‹_norm': 0.01,
        'å¹³å‡é—¨ç¥¨ä»·æ ¼_norm': 0.005,
        'æœåŠ¡è´¨é‡æŒ‡æ•°_norm': 0.005,
    }
    
    # ç»¼åˆè¯„åˆ†è®¡ç®—
    city_features_df['å¤–å›½æ¸¸å®¢å¸å¼•åŠ›å¾—åˆ†'] = 0
    for col, weight in weights.items():
        if col in city_features_df.columns:
            city_features_df['å¤–å›½æ¸¸å®¢å¸å¼•åŠ›å¾—åˆ†'] += city_features_df[col] * weight
    
    return city_features_df

def main_foreign_tourist_evaluation(folder_path):
    """
    ä¸»å‡½æ•°ï¼šå¤–å›½æ¸¸å®¢è§†è§’çš„åŸå¸‚ç»¼åˆè¯„ä»·
    """
    print("å¼€å§‹åŸºäºå¤–å›½æ¸¸å®¢åå¥½çš„åŸå¸‚ç»¼åˆè¯„ä»·...")
    print("è¯„ä»·ç»´åº¦ï¼šæ™¯ç‚¹å¸å¼•åŠ›ã€äººæ–‡åº•è•´ã€è‡ªç„¶ç¯å¢ƒã€åŸå¸‚è§„æ¨¡ã€äº¤é€šä¾¿åˆ©ã€æ°”å€™ã€ç¾é£Ÿæ–‡åŒ–")
    print("="*80)
    
    # å¤„ç†æ‰€æœ‰åŸå¸‚
    city_features_df = process_all_cities_comprehensive(folder_path)
    
    if city_features_df.empty:
        print("æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åŸå¸‚æ•°æ®æ–‡ä»¶")
        return
    
    print(f"\næˆåŠŸå¤„ç† {len(city_features_df)} ä¸ªåŸå¸‚")
    
    # ç»¼åˆè¯„ä»·
    city_features_df = comprehensive_evaluation_for_foreign_tourists(city_features_df)
    
    # æ’åºå¹¶è¾“å‡ºTOP50
    top50 = city_features_df.sort_values('å¤–å›½æ¸¸å®¢å¸å¼•åŠ›å¾—åˆ†', ascending=False).head(50)
    
    print("\nğŸŒŸ æœ€ä»¤å¤–å›½æ¸¸å®¢å‘å¾€çš„50ä¸ªä¸­å›½åŸå¸‚ ğŸŒŸ")
    print("="*80)
    
    for i, (idx, row) in enumerate(top50.iterrows(), 1):
        print(f"{i:2d}. {row['city']:12s} - ç»¼åˆå¾—åˆ†: {row['å¤–å›½æ¸¸å®¢å¸å¼•åŠ›å¾—åˆ†']:.4f} "
              f"(æ™¯ç‚¹{int(row['æ™¯ç‚¹æ€»æ•°'])}, è¯„åˆ†{row['å¹³å‡æ™¯ç‚¹è¯„åˆ†']:.1f}, "
              f"æ–‡åŒ–{row['å†å²æ–‡åŒ–æŒ‡æ•°']:.2f})")
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    output_columns = ['city', 'å¤–å›½æ¸¸å®¢å¸å¼•åŠ›å¾—åˆ†', 'æ™¯ç‚¹æ€»æ•°', 'å¹³å‡æ™¯ç‚¹è¯„åˆ†', 'é«˜è´¨é‡æ™¯ç‚¹æ•°',
                     'å†å²æ–‡åŒ–æŒ‡æ•°', 'è‡ªç„¶ç”Ÿæ€æŒ‡æ•°', 'ç¾é£Ÿæ–‡åŒ–æŒ‡æ•°', 'å…è´¹æ™¯ç‚¹æ¯”ä¾‹']
    
    top50[output_columns].to_csv(
        'top50_cities_for_foreign_tourists_comprehensive.csv', 
        index=False, 
        encoding='utf-8-sig'
    )
    
    # ä¿å­˜å®Œæ•´è¯„ä»·æ•°æ®
    city_features_df.to_csv('all_cities_foreign_tourist_evaluation.csv', index=False, encoding='utf-8-sig')
    
    print(f"\nğŸ“Š è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: top50_cities_for_foreign_tourists_comprehensive.csv")
    print(f"ğŸ“Š å®Œæ•´æ•°æ®å·²ä¿å­˜åˆ°: all_cities_foreign_tourist_evaluation.csv")
    
    return top50

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # æŒ‡å®šåŒ…å«æ‰€æœ‰"åŸå¸‚å.csv"æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„
    folder_path = "./cities_data"  # è¯·ä¿®æ”¹ä¸ºå®é™…è·¯å¾„
    
    top50_cities = main_foreign_tourist_evaluation(folder_path)
    
    # è¾“å‡ºç®€è¦åˆ†æ
    if top50_cities is not None and not top50_cities.empty:
        print("\nğŸ“ˆ TOP10åŸå¸‚ç‰¹è‰²åˆ†æ:")
        top10 = top50_cities.head(10)
        for idx, row in top10.iterrows():
            specialty = []
            if row['å†å²æ–‡åŒ–æŒ‡æ•°'] > 0.5: specialty.append("å†å²æ‚ ä¹…")
            if row['è‡ªç„¶ç”Ÿæ€æŒ‡æ•°'] > 0.5: specialty.append("ç”Ÿæ€ä¼˜ç¾") 
            if row['ç¾é£Ÿæ–‡åŒ–æŒ‡æ•°'] > 0.3: specialty.append("ç¾é£Ÿä¸°å¯Œ")
            if row['å…è´¹æ™¯ç‚¹æ¯”ä¾‹'] > 0.3: specialty.append("æ€§ä»·æ¯”é«˜")
            
            print(f"   {row['city']}: {', '.join(specialty) if specialty else 'ç»¼åˆå‘å±•'}")